{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align: right;\"> &#9989; Jared Evans</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSE 202 Final (Section 002 - Spring 2025) (80 points total)\n",
    "\n",
    "The goal of this final is to give you the opportunity to test out some of the skills that you've developed having now finished CMSE 202. In particular, you'll be committing and pushing repository changes to a GitHub repository, working with data to build a network graph, performing regression analysis, and classifying data using a machine learning classifier. You should find that you have all of the skills necessary to complete this exam having completed the second half of CMSE 202!\n",
    "\n",
    "You are encouraged to look through the entire exam before you get started so that you can appropriately budget your time and understand the broad goals of the exam. Once you've read through it, you'll probably want to make sure you do Part 1 first to ensure that your GitHub repository is working correctly. Let your instructor know right away if you run into issues!\n",
    "\n",
    "**Important note about using online resources**: This exam is \"open internet\". That means that you can look up documentation, google how to accomplish certain Python tasks, etc. Being able to effectively use the internet for computational modeling and data science is a very important skill, so we want to make sure you have the opportunity to exercise that skill. You can also use _your version_ of past CMSE 202 assignments and the CMSE 202 course materials as a resource! **However: The use of any person-to-person communication software or is absolutely not acceptable.** If you are seen accessing your email, using a collaborative cloud storage or document software (e.g. Slack, Google Documents) you will be at risk for receiving a zero on the exam. Regardless of what resources you use whether they are ai or stackexchange, CITE THEM PLEASE. You will get marked down if you provide a response that looks copy and pasted without a citation. If you are unsure of how to do a citation or if your citation is good enough, ask your professor or instructional staff for help.\n",
    "\n",
    "**Keep your eyes on your screen!** Unfortunately, there isn't enough space in the room for everyone to sit at their own table so please do your best to keep your eyes on your own screen. This exam is designed to give *you* the opportunity to show the instructor what you can do and you should hold yourself accountable for maintaining a high level of academic integrity. If any of the instructors observe suspicious behavior, you will, again, risk receiving a zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Part 0: Academic integrity statement\n",
    "\n",
    "Read the following statement and edit the markdown text to put your name in the statement. This is your commitment to doing your own authentic work on this exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I, **Jared Evans**, affirm that this exam represents my own authetic work, without the use of any unpermitted aids or resources or person-to-person communication. I understand that this exam an an opportunity to showcase my own progress in developing and improving my computational skills and have done my best to demonstrate those skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Part 1: Add to your Git repository to track your progress on your exam (7 points)\n",
    "\n",
    "Before you get to far along in the exam, you're going to add it to the `cmse202-s25-turnin` repository you created in class so that you can track your progress on the exam and preserve the final version that you turn in. In order to do this you need to\n",
    "\n",
    "**&#9989; Do the following**:\n",
    "\n",
    "1. Navigate to your `cmse202-s25-turnin` repository and create a new directory called `final`. You may have already done this in the midterm. If you have, then good job move on to the next part!\n",
    "2. Move this notebook into that **new directory** in your repository, then **add it and commit it to your repository**.\n",
    "1. Finally, to test that everything is working, \"git push\" the file so that it ends up in your GitHub repository.\n",
    "\n",
    "**Important**: Double check you've added your Professor and your TA as collaborators to your \"turnin\" respository (you should have done this previously).\n",
    "\n",
    "**Also important**: Make sure that the version of this notebook that you are working on is the same one that you just added to your repository! If you are working on a different copy of the noteobok, **none of your changes will be tracked**!\n",
    "\n",
    "If everything went as intended, the file should now show up on your GitHub account in the \"`cmse202-s25-turnin`\" repository inside the `final` directory that you just created. Periodically, **you'll be asked to commit your changes to the repository and push them to the remote GitHub location**. Of course, you can always commit your changes more often than that, if you wish.  It can be good to get into a habit of committing your changes any time you make a significant modification, or when you stop working on the project for a bit.\n",
    "\n",
    "&#9989; **Do this**: Before you move on, put the command that your instructor should run to clone your repository in the markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` bash\n",
    "# Put the command for cloning your repository here!\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Part 2: Graph Theory and Networks (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 2.1 (9 points)**: We want you to make a very basic model of the personal network you have built this term. Using Networkx, visualize a network that has at least five (including yourself) CMSE202 classmates you have met and worked with this term. There should be an edge connecting you to all of the other classmates. Add at least one edge between two classmates that know each other (besides yourself). If you do not know names, use your group project member names to make this graph. The Day 10 ICA and PCA should help with doing this. I reccomend using dictionaries to make your network. See if you can display the names of this network on your diagram as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Put your code for Question 2.1 here\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "network = ['Jared Evans', 'Sam Parks', 'Fredrick Babe', 'Aidan Kilinger', 'Nicholas Nulsen']\n",
    "\n",
    "edges = [('Jared Evans', 'Sam Parks'),\n",
    "        ('Jared Evans','Fredrick Babe'),\n",
    "        ('Jared Evans','Aidan Kilinger'),\n",
    "        ('Jared Evans','Nicholas Nulsen'),\n",
    "        ('Fredrick Babe','Aidan Kilinger'),\n",
    "        ]\n",
    "\n",
    "\n",
    "\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, with_labels=True, node_color='skyblue', edge_color='gray', node_size=2000, font_size=10, font_weight='bold')\n",
    "plt.title(\"My Network\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"**Committing Part 2**\", and push the changes to GitHub.\n",
    "\n",
    "\n",
    "If committing and/or pushing isn't working for you, write down the complete commands in this cell that would have committed your changes (with the commit message) and pushed them to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Part 3: Regression Analysis on Data (27 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal for this part is to do a multivariate linear regression, also known as multiple linear regression, to understand the relation between renting a bike and other factors. You can download the dataset from this URL:\n",
    "\n",
    "`https://raw.githubusercontent.com/gambre11/CMSE202/refs/heads/main/day.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.1 (3 points)**: To get started, **download the `day.csv` file and place it in the same directory as your notebook**, then **read in the `day.csv` dataset and name it `bike_data`** and finally **display the first few rows of the data**. You can use `Pandas` for this task or any other Python tool you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1        0        6           0   \n",
       "1        2  2011-01-02       1   0     1        0        0           0   \n",
       "2        3  2011-01-03       1   0     1        0        1           1   \n",
       "3        4  2011-01-04       1   0     1        0        2           1   \n",
       "4        5  2011-01-05       1   0     1        0        3           1   \n",
       "\n",
       "   weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "0           2  0.344167  0.363625  0.805833   0.160446     331         654   \n",
       "1           2  0.363478  0.353739  0.696087   0.248539     131         670   \n",
       "2           1  0.196364  0.189405  0.437273   0.248309     120        1229   \n",
       "3           1  0.200000  0.212122  0.590435   0.160296     108        1454   \n",
       "4           1  0.226957  0.229270  0.436957   0.186900      82        1518   \n",
       "\n",
       "    cnt  \n",
       "0   985  \n",
       "1   801  \n",
       "2  1349  \n",
       "3  1562  \n",
       "4  1600  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Put your code here\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "bike_new = pd.read_csv('day.csv')\n",
    "\n",
    "bike_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information for this dataset can be found here: https://www.kaggle.com/datasets/lakshmi25npathi/bike-sharing-dataset/data\n",
    "\n",
    "You will be trying to predict `cnt` (which is the number of bike rentals) using linear regression with the features.\n",
    "\n",
    "\n",
    "&#9989; **Question 3.2 (2 points)**: Remove the columns `dteday`, `instant`,`casual`, and `registered` from the data you loaded in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   season  yr  mnth  holiday  weekday  workingday  weathersit      temp  \\\n",
      "0       1   0     1        0        6           0           2  0.344167   \n",
      "1       1   0     1        0        0           0           2  0.363478   \n",
      "2       1   0     1        0        1           1           1  0.196364   \n",
      "3       1   0     1        0        2           1           1  0.200000   \n",
      "4       1   0     1        0        3           1           1  0.226957   \n",
      "\n",
      "      atemp       hum  windspeed   cnt  \n",
      "0  0.363625  0.805833   0.160446   985  \n",
      "1  0.353739  0.696087   0.248539   801  \n",
      "2  0.189405  0.437273   0.248309  1349  \n",
      "3  0.212122  0.590435   0.160296  1562  \n",
      "4  0.229270  0.436957   0.186900  1600  \n"
     ]
    }
   ],
   "source": [
    "### Put your code here\n",
    "bike_new = bike_new.drop(columns=['dteday', 'instant', 'casual', 'registered'])\n",
    "print(bike_new.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; Run this following code cell. This is taking some columns and separating the data. You will likely need to change the variable name to match the variable name of your data set though so pay attention to everywhere it mentions `bike_new`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "bike_new['season']=bike_new['season'].astype('category')\n",
    "bike_new['weathersit']=bike_new['weathersit'].astype('category')\n",
    "bike_new['mnth']=bike_new['mnth'].astype('category')\n",
    "bike_new['weekday']=bike_new['weekday'].astype('category')\n",
    "\n",
    "bike_new = pd.get_dummies(bike_new, drop_first=True)\n",
    "bike_new.replace({False: 0, True: 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.3 (3 points)**: **Construct two data frames** using the loaded and cleaned data: one named `labels` and the other named `features`. The `labels` data frame should consist solely of the `cnt` column, while the `features` data frame should contain all the other columns. **Display the first few lines of these data frames.** Note the pandas `.pop` method may be helpful here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     985\n",
      "1     801\n",
      "2    1349\n",
      "3    1562\n",
      "4    1600\n",
      "Name: cnt, dtype: int64\n",
      "   season  yr  mnth  holiday  weekday  workingday  weathersit      temp  \\\n",
      "0       1   0     1        0        6           0           2  0.344167   \n",
      "1       1   0     1        0        0           0           2  0.363478   \n",
      "2       1   0     1        0        1           1           1  0.196364   \n",
      "3       1   0     1        0        2           1           1  0.200000   \n",
      "4       1   0     1        0        3           1           1  0.226957   \n",
      "\n",
      "      atemp       hum  windspeed  \n",
      "0  0.363625  0.805833   0.160446  \n",
      "1  0.353739  0.696087   0.248539  \n",
      "2  0.189405  0.437273   0.248309  \n",
      "3  0.212122  0.590435   0.160296  \n",
      "4  0.229270  0.436957   0.186900  \n"
     ]
    }
   ],
   "source": [
    "### Put your code here\n",
    "import pandas as pd\n",
    "\n",
    "bike_data = pd.read_csv('day.csv')\n",
    "bike_data = bike_data.drop(columns=['dteday', 'instant', 'casual', 'registered'])\n",
    "\n",
    "labels = bike_data['cnt']\n",
    "features = bike_data.drop(columns=['cnt'])\n",
    "\n",
    "print(labels.head())\n",
    "print(features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will fit the data using the ordinary least squares model `OLS` in `statsmodel`. \n",
    "\n",
    "&#9989; **Question 3.4 (2 point)**: Before proceeding, **add a column of constants** (set to 1.0) to the `features` data frame. You learned about a `statsmodels` function in class that can accomplish this task. Label the modified data frame as `features_const`. **Display** `features_const` to verify that the new column is indeed added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   const  season  yr  mnth  holiday  weekday  workingday  weathersit  \\\n",
      "0    1.0       1   0     1        0        6           0           2   \n",
      "1    1.0       1   0     1        0        0           0           2   \n",
      "2    1.0       1   0     1        0        1           1           1   \n",
      "3    1.0       1   0     1        0        2           1           1   \n",
      "4    1.0       1   0     1        0        3           1           1   \n",
      "\n",
      "       temp     atemp       hum  windspeed  \n",
      "0  0.344167  0.363625  0.805833   0.160446  \n",
      "1  0.363478  0.353739  0.696087   0.248539  \n",
      "2  0.196364  0.189405  0.437273   0.248309  \n",
      "3  0.200000  0.212122  0.590435   0.160296  \n",
      "4  0.226957  0.229270  0.436957   0.186900  \n"
     ]
    }
   ],
   "source": [
    "### Put your code here\n",
    "import statsmodels.api as sm \n",
    "\n",
    "\n",
    "features_const = sm.add_constant(features)\n",
    "\n",
    "\n",
    "print(features_const.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will perform the actual fit.\n",
    "\n",
    "&#9989; **Question 3.5 (4 points)**: Using `statsmodels` `OLS`, **perform a fit** using `labels` (containing `cnt`) as the dependent variable and `features_const` as the independent variable. **Print the fit** using `summary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    cnt   R-squared:                       0.800\n",
      "Model:                            OLS   Adj. R-squared:                  0.797\n",
      "Method:                 Least Squares   F-statistic:                     261.9\n",
      "Date:                Wed, 30 Apr 2025   Prob (F-statistic):          7.80e-243\n",
      "Time:                        15:32:22   Log-Likelihood:                -5981.0\n",
      "No. Observations:                 731   AIC:                         1.199e+04\n",
      "Df Residuals:                     719   BIC:                         1.204e+04\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       1469.0031    240.218      6.115      0.000     997.390    1940.616\n",
      "season       509.7752     54.757      9.310      0.000     402.272     617.278\n",
      "yr          2040.7034     65.185     31.306      0.000    1912.727    2168.680\n",
      "mnth         -38.9796     17.079     -2.282      0.023     -72.510      -5.449\n",
      "holiday     -518.9919    201.040     -2.582      0.010    -913.688    -124.296\n",
      "weekday       69.0622     16.299      4.237      0.000      37.063     101.061\n",
      "workingday   120.3570     72.007      1.671      0.095     -21.013     261.727\n",
      "weathersit  -610.9870     78.363     -7.797      0.000    -764.835    -457.139\n",
      "temp        2028.9161   1403.671      1.445      0.149    -726.867    4784.699\n",
      "atemp       3573.2743   1589.389      2.248      0.025     452.877    6693.671\n",
      "hum        -1018.8616    313.995     -3.245      0.001   -1635.318    -402.405\n",
      "windspeed  -2557.5691    456.278     -5.605      0.000   -3453.365   -1661.774\n",
      "==============================================================================\n",
      "Omnibus:                       88.811   Durbin-Watson:                   0.967\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              180.069\n",
      "Skew:                          -0.717   Prob(JB):                     7.92e-40\n",
      "Kurtosis:                       4.964   Cond. No.                         561.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "### Put your code here\n",
    "model = sm.OLS(labels, features_const).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.5 (2 points)**: Among all the features, is there one or more that are significantly less important than others? justify your answer with a sentence or two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> yeah, temp looks like its not that important since its p-value is 0.149, which is higher than the usual 0.05 cutoff. workingday is also kinda weak at 0.095, so it might not matter much either. the rest seem pretty solid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.6 (3 points)**: **Remove the \"least important\" features**, then **fit the model again** and **print the fit** using `summary()` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    cnt   R-squared:                       0.799\n",
      "Model:                            OLS   Adj. R-squared:                  0.796\n",
      "Method:                 Least Squares   F-statistic:                     318.2\n",
      "Date:                Wed, 30 Apr 2025   Prob (F-statistic):          2.87e-244\n",
      "Time:                        15:36:16   Log-Likelihood:                -5983.5\n",
      "No. Observations:                 731   AIC:                         1.199e+04\n",
      "Df Residuals:                     721   BIC:                         1.203e+04\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       1458.3767    228.137      6.393      0.000    1010.484    1906.269\n",
      "season       509.7017     54.867      9.290      0.000     401.984     617.420\n",
      "yr          2041.0816     65.316     31.249      0.000    1912.849    2169.314\n",
      "mnth         -39.2280     17.113     -2.292      0.022     -72.824      -5.632\n",
      "holiday     -592.0094    195.080     -3.035      0.002    -975.002    -209.017\n",
      "weekday       70.5067     16.309      4.323      0.000      38.488     102.525\n",
      "weathersit  -598.2989     78.304     -7.641      0.000    -752.029    -444.569\n",
      "atemp       5868.6082    220.345     26.634      0.000    5436.014    6301.202\n",
      "hum        -1060.9489    313.980     -3.379      0.001   -1677.373    -444.525\n",
      "windspeed  -2466.4982    450.986     -5.469      0.000   -3351.900   -1581.096\n",
      "==============================================================================\n",
      "Omnibus:                       98.079   Durbin-Watson:                   0.975\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              203.980\n",
      "Skew:                          -0.773   Prob(JB):                     5.08e-45\n",
      "Kurtosis:                       5.075   Cond. No.                         130.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "### Put your code here\n",
    "reduced_features = features_const.drop(columns=['temp', 'workingday'])\n",
    "\n",
    "reduced_model = sm.OLS(labels, reduced_features).fit()\n",
    "\n",
    "\n",
    "print(reduced_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.7 (3 points)**: Discuss the difference in fit quality between the two fits. Did the second fit (with \"least important\" feature removed) outperform or underperform compared to the other? Describe how you evaluated the quality based on the fit statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> Do This The second model didn't change that much. The r squared only dropped to 0.799 compared to 0.800, indicating minimal change. Adjusted R stayed virtually the same as well, meaning, removing those variables didn't change much of anything at all. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 3.8 (5 points)**: What does this all mean? What is your best R-squared value or adjusted R-squared value? What can we say about the data and how it might be related? What does it mean when people say that correlation is not causation? Please try to answer these questions the best that you can in a paragraph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> our best adjusted R-squared value is 0.796, which means about 80% of the variation in bike rental counts can be explained by the features we used, like temperature, season, and humidity. This means these factors are the main reasons why people rent bikes or not. Just because the temperatures are high doesn't mean more bikes will be rented other factors in the weather also matter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"**Committing Part 3**\", and push the changes to GitHub.\n",
    "\n",
    "\n",
    "If committing and/or pushing isn't working for you, write down the complete commands in this cell that would have committed your changes (with the commit message) and pushed them to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Part 4: Support vector machine (SVM) classification (34 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the exam, we will use a support vector machine (SVM) classifier to identify emails as spam or not based on various email features. We will be using the UC Irvine Machine Learning Repository Spambase Dataset. More info about this dataset can be found here https://archive.ics.uci.edu/dataset/94/spambase. \n",
    "\n",
    "To get started, download the `spambasedata.csv` file from the link below (or D2L) and place it in the same directory as your notebook. \n",
    "\n",
    "`https://raw.githubusercontent.com/gambre11/CMSE202/refs/heads/main/spambasedata.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.1 (2 points)**: Read in the `spambase.csv` dataset into a `Pandas` `DataFrame` and display the first few rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.64</th>\n",
       "      <th>0.64.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.32</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>...</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>0.43</th>\n",
       "      <th>0.778</th>\n",
       "      <th>0.44</th>\n",
       "      <th>0.45</th>\n",
       "      <th>3.756</th>\n",
       "      <th>61</th>\n",
       "      <th>278</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.671</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.450</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.022</td>\n",
       "      <td>9.744</td>\n",
       "      <td>445</td>\n",
       "      <td>1257</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.729</td>\n",
       "      <td>43</td>\n",
       "      <td>749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.312</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.243</td>\n",
       "      <td>11</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows  58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  0.64  0.64.1  0.1  0.32   0.2   0.3   0.4   0.5   0.6  ...   0.41  \\\n",
       "0   0.21  0.28    0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.000   \n",
       "1   0.06  0.00    0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.010   \n",
       "2   0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
       "3   0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
       "4   0.00  0.00    0.00  0.0  1.85  0.00  0.00  1.85  0.00  0.00  ...  0.000   \n",
       "5   0.00  0.00    0.00  0.0  1.92  0.00  0.00  0.00  0.00  0.64  ...  0.000   \n",
       "6   0.00  0.00    0.00  0.0  1.88  0.00  0.00  1.88  0.00  0.00  ...  0.000   \n",
       "7   0.15  0.00    0.46  0.0  0.61  0.00  0.30  0.00  0.92  0.76  ...  0.000   \n",
       "8   0.06  0.12    0.77  0.0  0.19  0.32  0.38  0.00  0.06  0.00  ...  0.040   \n",
       "9   0.00  0.00    0.00  0.0  0.00  0.00  0.96  0.00  0.00  1.92  ...  0.000   \n",
       "10  0.00  0.00    0.25  0.0  0.38  0.25  0.25  0.00  0.00  0.00  ...  0.022   \n",
       "\n",
       "     0.42  0.43  0.778   0.44   0.45  3.756   61   278  1  \n",
       "0   0.132   0.0  0.372  0.180  0.048  5.114  101  1028  1  \n",
       "1   0.143   0.0  0.276  0.184  0.010  9.821  485  2259  1  \n",
       "2   0.137   0.0  0.137  0.000  0.000  3.537   40   191  1  \n",
       "3   0.135   0.0  0.135  0.000  0.000  3.537   40   191  1  \n",
       "4   0.223   0.0  0.000  0.000  0.000  3.000   15    54  1  \n",
       "5   0.054   0.0  0.164  0.054  0.000  1.671    4   112  1  \n",
       "6   0.206   0.0  0.000  0.000  0.000  2.450   11    49  1  \n",
       "7   0.271   0.0  0.181  0.203  0.022  9.744  445  1257  1  \n",
       "8   0.030   0.0  0.244  0.081  0.000  1.729   43   749  1  \n",
       "9   0.000   0.0  0.462  0.000  0.000  1.312    6    21  1  \n",
       "10  0.044   0.0  0.663  0.000  0.000  1.243   11   184  1  \n",
       "\n",
       "[11 rows x 58 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Put your code for Question 4.1 here\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "spam_data = pd.read_csv('spambasedata.csv')\n",
    "\n",
    "spam_data.head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.2 (2 points)**: The following cell contains a list with the names of every column in this dataset. Add these column names to your data that you have read in, and display your data again. Double check and make sure you are not losing any data when doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"word_freq_make\", \"word_freq_address\", \"word_freq_all\", \"word_freq_3d\", \n",
    "                      \"word_freq_our\", \"word_freq_over\", \"word_freq_remove\", \"word_freq_internet\", \n",
    "                      \"word_freq_order\", \"word_freq_mail\", \"word_freq_receive\", \"word_freq_will\", \n",
    "                      \"word_freq_people\", \"word_freq_report\", \"word_freq_addresses\", \"word_freq_free\", \n",
    "                      \"word_freq_business\", \"word_freq_email\", \"word_freq_you\", \"word_freq_credit\", \n",
    "                      \"word_freq_your\", \"word_freq_font\", \"word_freq_000\", \"word_freq_money\", \"word_freq_hp\", \n",
    "                      \"word_freq_hpl\", \"word_freq_george\", \"word_freq_650\", \"word_freq_lab\", \"word_freq_labs\", \n",
    "                      \"word_freq_telnet\", \"word_freq_857\", \"word_freq_data\", \"word_freq_415\", \"word_freq_85\", \n",
    "                      \"word_freq_technology\", \"word_freq_1999\", \"word_freq_parts\", \"word_freq_pm\", \"word_freq_direct\",\n",
    "                      \"word_freq_cs\", \"word_freq_meeting\", \"word_freq_original\", \"word_freq_project\", \"word_freq_re\", \n",
    "                      \"word_freq_edu\", \"word_freq_table\", \"word_freq_conference\", \"char_freq_;\", \"char_freq_(\", \n",
    "                      \"char_freq_[\", \"char_freq_!\", \"char_freq_$\", \"char_freq_hash\", \"capital_run_length_average\", \n",
    "                      \"capital_run_length_longest\", \"capital_run_length_total\", \"spam\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.3 (2 points)**: How many rows of data are there? How many emails are marked as spam and what is this percentage compared to the entire dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total emails: 4600\n",
      "Spam emails: 1812\n",
      "Percentage spam: 39.39%\n"
     ]
    }
   ],
   "source": [
    "### Put your work and answer to Question 4.3 here\n",
    "\n",
    "spam_data.columns = column_names\n",
    "\n",
    "total_emails = len(spam_data)\n",
    "spam_count = spam_data['spam'].sum()\n",
    "spam_percentage = (spam_count / total_emails) * 100\n",
    "\n",
    "print(\"Total emails:\", total_emails)\n",
    "print(\"Spam emails:\", spam_count)\n",
    "print(\"Percentage spam: {:.2f}%\".format(spam_percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.4 (2 points)**: Our goal is to classify the `spam` of the email given the other 57 features. Create a variable with all of the columns of the `DataFrame` except for `spam`,  and another variable with just the `spam` column of the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code for Question 4.4 here\n",
    "\n",
    "X = spam_data.drop(columns=['spam'])\n",
    "\n",
    "y = spam_data['spam']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is properly loaded into Python, we need to perform a **train-test-split** so that we can build our SVM classifier and test it.\n",
    "\n",
    "&#9989; **Question 4.5 (4 points)**: Use the `train_test_split()` method from `sklearn.model_selection` like we did in class. Use a `train_size` of `0.78` and `random_state` of `1616`. You should now have training features, testing features, training labels, and testing labels. Finally, **print the shape of your training features, training labels, testing features, and testing labels** to verify that your train-test-split did what it was supposed to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3588, 57)\n",
      "y_train shape: (3588,)\n",
      "X_test shape: (1012, 57)\n",
      "y_test shape: (1012,)\n"
     ]
    }
   ],
   "source": [
    "### Put your code for Question 4.5 here\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.78, random_state=1616\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.6 (6 points)**: Fit an SVM classifier (using the `sklearn` `SVC` class) to the dataset. Use a `linear` kernel and set the hyper-parameter to be `C=0.001.` Then **fit the SVM using your training set** and use the resulting SVM to **predict the labels for the testing set** so you get predicted labels for the testing set. Finally, **print the fit statistics** using the `confusion_matrix()` and `classification_report()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[565  41]\n",
      " [ 99 307]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89       606\n",
      "           1       0.88      0.76      0.81       406\n",
      "\n",
      "    accuracy                           0.86      1012\n",
      "   macro avg       0.87      0.84      0.85      1012\n",
      "weighted avg       0.86      0.86      0.86      1012\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Put your code for Question 4.6 here\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=0.001)\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.7 (2 points)**: Create two more SVM classifiers and test them by repeating your work from Question 4.6, but this time set the hyper-parameters to be `C=0.01.` and `C=0.1.` Again, **print the fit statistics** using the `confusion_matrix()` and `classification_report()` methods. Note that this might take 30 seconds to a minute to run. If it takes longer than 2 minutes, flag an instructor for help. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for C = 0.01\n",
      "[[574  32]\n",
      " [ 57 349]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       606\n",
      "           1       0.92      0.86      0.89       406\n",
      "\n",
      "    accuracy                           0.91      1012\n",
      "   macro avg       0.91      0.90      0.91      1012\n",
      "weighted avg       0.91      0.91      0.91      1012\n",
      "\n",
      "Results for C = 0.1\n",
      "[[575  31]\n",
      " [ 46 360]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       606\n",
      "           1       0.92      0.89      0.90       406\n",
      "\n",
      "    accuracy                           0.92      1012\n",
      "   macro avg       0.92      0.92      0.92      1012\n",
      "weighted avg       0.92      0.92      0.92      1012\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Put your code for Question 4.7 here\\\n",
    "\n",
    "\n",
    "model_001 = SVC(kernel='linear', C=0.01)\n",
    "model_001.fit(X_train, y_train)\n",
    "pred_001 = model_001.predict(X_test)\n",
    "\n",
    "print(\"Results for C = 0.01\")\n",
    "print(confusion_matrix(y_test, pred_001))\n",
    "print(classification_report(y_test, pred_001))\n",
    "\n",
    "\n",
    "model_01 = SVC(kernel='linear', C=0.1)\n",
    "model_01.fit(X_train, y_train)\n",
    "pred_01 = model_01.predict(X_test)\n",
    "\n",
    "print(\"Results for C = 0.1\")\n",
    "print(confusion_matrix(y_test, pred_01))\n",
    "print(classification_report(y_test, pred_01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.8 (6 points)**: Interpret the outputs of your classification reports and the confusion matrices. In particular: \n",
    "\n",
    "* From your classification report, talk about what the **precision**, **recall**, and **f1-score** mean in this context. Do not just give definitions.\n",
    "\n",
    "* From your confusion matrix, what do each of the four numbers represent in this context. Again do not give a broad definition.\n",
    "\n",
    "* How does your accuracy change as C changes? Why does this happen? What is the parameter C and what does increasing or decreasing its value represent when classifying data using SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> for C = 0.01, the model had 91% accuracy, and when we bumped C to 0.1, it went up to 92%. the precision tells us how many of the emails we predicted as spam were actually spam, and recall tells us how many actual spam emails we correctly caught. The f1 score is just the combination of the two. As for the confusion matrix, the top left number is true negatives the bottom right is true positives. The other two are false positive and and false negative. When we increased c the model got stricter and caught more spam, it did slightly better overall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "&#9989; **Question 4.9 (1 point)**: Suppose we wanted to try fitting a Support Vector Classifier for multiple choices of the kernel function and multiple choices for the values of the hyperparameter(s) (instead of just using a `linear` kernel with one value of `C`). We could write code with nested for loops to repeat the procedure with every combination of kernel function and hyperparameter value(s) we wanted to try. Name a method built into sklearn that will do this automatically. (We used this on an in-class assignment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> The method is GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "&#9989; **Question 4.10 (1 point)**: When filtering out spam emails, we want to minimize filtering out emails that may be important. What could we do to prioritize this? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> We could prioritize this by focusing on improving precision, so we reduce the number of legitimate emails that get incorrectly flagged as spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.11 (3 points)**: Both of the images below show the same two-dimensional dataset with two classes (solid blue squares and unfilled red circles) along with the decision boundary of a linear classifier. One classifier was generated via the Perceptron Learning Algorithm, and the other used a Support Vector Classifier. Which one is which? **Justify your answer!**\n",
    "\n",
    "Classifier A          | | Classifier B\n",
    ":-------------------------:|:---:|:-------------------------:\n",
    "![](https://i.ibb.co/R2BBsDC/Datapoints1-A.png)  | |  ![](https://i.ibb.co/mb9vcq4/Datapoints1-B.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> II think Classifier A is from the perceptron learning algorithm because the boundary looks like it just barely separates the classes and doesnt leave any extra margin. Classifier B looks like the support vector classifier since the line leaves space between the two groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 4.12 (3 points)**: Both of the images below show the same two-dimensional dataset with two classes (solid blue squares and unfilled red circles) along with the decision boundary of a linear Support Vector Classifier. One used the hyperparameter `C = 0.1`, and the other used the hyperparameter `C = 1000`. Which one is which? **Justify your answer!**\n",
    "\n",
    "Classifier X          | | Classifier Y\n",
    ":-------------------------:|:---:|:-------------------------:\n",
    "![](https://i.ibb.co/7pPCRwh/Datapoints2-A.png)  | |  ![](https://i.ibb.co/LSMBXzd/Datapoints2-B.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier X has a margin that cuts diagonally and misclassifies one blue square and one red circle, but it keeps the margin tighter to the data.\n",
    "\n",
    "Classifier Y misclassifies the same number of points, but the decision boundary is flatter and farther away from the closest points\n",
    "\n",
    "Classifier X is C = 1000 \n",
    "\n",
    "Classifier Y is C = 0.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### &#128721; STOP\n",
    "**Pause to commit your changes to your Git repository!**\n",
    "\n",
    "Take a moment to save your notebook, commit the changes to your Git repository using the commit message \"**Committing Part 4**\", and push the changes to GitHub.\n",
    "\n",
    "\n",
    "If committing and/or pushing isn't working for you, write down the complete commands in this cell that would have committed your changes (with the commit message) and pushed them to GitHub.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Part 5: Principal Component Analysis (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **Question 5 (5 points)**: What was the point of doing Principal Component Analysis on our face data from our day 23 ICA? What does Principal Component Analysis help us do? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=+3>&#9998;</font> ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You're done! Congrats on finishing your CMSE 202 Final!\n",
    "\n",
    "Make sure all of your changes to your repository are committed and pushed to GitHub (or that you wrote down the commands that would have done that after each part). Also upload a copy of this notebook to the dropbox on D2L in case something went wrong with your repository or if you couldn't get the repository to work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
